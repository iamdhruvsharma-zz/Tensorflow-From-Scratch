{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "mnist_with_keras_DXT.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo81MmN8rBJj",
        "colab_type": "text"
      },
      "source": [
        "Visit: https://github.com/hse-aml/intro-to-dl/blob/master/README.md for configuration details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3QMeh3CrNxV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "f10eacd1-6fb7-46cc-cf95-5ba30ca1351f"
      },
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "# please, uncomment the week you're working on\n",
        "# setup_google_colab.setup_week1()\n",
        "setup_google_colab.setup_week2()\n",
        "# setup_google_colab.setup_week2_honor()\n",
        "# setup_google_colab.setup_week3()\n",
        "# setup_google_colab.setup_week4()\n",
        "# setup_google_colab.setup_week5()\n",
        "# setup_google_colab.setup_week6()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shred: setup_google_colab.py: failed to open for writing: No such file or directory\n",
            "--2020-05-01 08:36:18--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3636 (3.6K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "setup_google_colab. 100%[===================>]   3.55K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-05-01 08:36:19 (36.1 MB/s) - ‘setup_google_colab.py’ saved [3636/3636]\n",
            "\n",
            "**************************************************\n",
            "inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "**************************************************\n",
            "cifar-10-batches-py.tar.gz\n",
            "**************************************************\n",
            "mnist.npz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2Pa_i0bqxG6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b0ae93c1-f6f8-41f6-a937-bcbfbd2c02fc"
      },
      "source": [
        "# set tf 1.x for colab\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VFu79dNqxG-",
        "colab_type": "text"
      },
      "source": [
        "# MNIST digits classification with Keras\n",
        "\n",
        "We don't expect you to code anything here because you've already solved it with TensorFlow.\n",
        "\n",
        "But you can appreciate how simpler it is with Keras.\n",
        "\n",
        "We'll be happy if you play around with the architecture though, there're some tips at the end."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAejn4smqxG_",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week2/v2/images/mnist_sample.png?raw=1\" style=\"width:30%\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPo8mVj7qxG_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "64de74e2-29eb-4e3a-c231-d83b4c34f53b"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "print(\"We're using TF\", tf.__version__)\n",
        "import keras\n",
        "print(\"We are using Keras\", keras.__version__)\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"../..\")\n",
        "import keras_utils\n",
        "from keras_utils import reset_tf_session"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We're using TF 1.15.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "We are using Keras 2.0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNpb2wFhYtGv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c91bf834-7a70-4566-d54f-59533a54a591"
      },
      "source": [
        "# GPU Training\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wcHx8MuqxHC",
        "colab_type": "text"
      },
      "source": [
        "# Look at the data\n",
        "\n",
        "In this task we have 50000 28x28 images of digits from 0 to 9.\n",
        "We will train a classifier on this data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSZA3ol6qxHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import preprocessed_mnist\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = preprocessed_mnist.load_dataset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p78Tqa7gqxHE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        },
        "outputId": "b54402f8-0043-4238-be60-50f3dbd28c4b"
      },
      "source": [
        "# X contains rgb values divided by 255\n",
        "print(\"X_train [shape %s] sample patch:\\n\" % (str(X_train.shape)), X_train[1, 15:20, 5:10])\n",
        "print(\"A closeup of a sample patch:\")\n",
        "plt.imshow(X_train[1, 15:20, 5:10], cmap=\"Greys\")\n",
        "plt.show()\n",
        "print(\"And the whole sample:\")\n",
        "plt.imshow(X_train[1], cmap=\"Greys\")\n",
        "plt.show()\n",
        "print(\"y_train [shape %s] 10 samples:\\n\" % (str(y_train.shape)), y_train[:10])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train [shape (50000, 28, 28)] sample patch:\n",
            " [[0.         0.29803922 0.96470588 0.98823529 0.43921569]\n",
            " [0.         0.33333333 0.98823529 0.90196078 0.09803922]\n",
            " [0.         0.33333333 0.98823529 0.8745098  0.        ]\n",
            " [0.         0.33333333 0.98823529 0.56862745 0.        ]\n",
            " [0.         0.3372549  0.99215686 0.88235294 0.        ]]\n",
            "A closeup of a sample patch:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "And the whole sample:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "y_train [shape (50000,)] 10 samples:\n",
            " [5 0 4 1 9 2 1 3 1 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSuT-sbxqxHH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "1ecac8f6-c420-4a4e-9e24-c21c9f44184d"
      },
      "source": [
        "# flatten images\n",
        "X_train_flat = X_train.reshape((X_train.shape[0], -1))\n",
        "print(X_train_flat.shape)\n",
        "\n",
        "X_val_flat = X_val.reshape((X_val.shape[0], -1))\n",
        "print(X_val_flat.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 784)\n",
            "(10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-3sqldOqxHK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "a6b9077d-8104-425d-fd0d-3ce3003cb342"
      },
      "source": [
        "# one-hot encode the target\n",
        "y_train_oh = keras.utils.to_categorical(y_train, 10)\n",
        "y_val_oh = keras.utils.to_categorical(y_val, 10)\n",
        "\n",
        "print(y_train_oh.shape)\n",
        "print(y_train_oh[:3], y_train[:3])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 10)\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]] [5 0 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-x8OQraPqxHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# building a model with keras\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.models import Sequential\n",
        "\n",
        "# we still need to clear a graph though\n",
        "s = reset_tf_session()\n",
        "\n",
        "model = Sequential()  # it is a feed-forward network without loops like in RNN\n",
        "model.add(Dense(256, input_shape=(784,)))  # the first layer must specify the input shape (replacing placeholders)\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fW5SxNMRqxHQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "1c565c0c-a78e-449a-875e-eb9e0b4e6bac"
      },
      "source": [
        "# you can look at all layers and parameter count\n",
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 256)               200960    \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 269,322\n",
            "Trainable params: 269,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GVD-T_-qxHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now we \"compile\" the model specifying the loss and optimizer\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy', # this is our cross-entropy\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']  # report accuracy during training\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3X3Ii8GqxHU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "896e9887-c84c-4af8-f91a-ffbecdb13577"
      },
      "source": [
        "# and now we can fit the model with model.fit()\n",
        "# and we don't have to write loops and batching manually as in TensorFlow\n",
        "model.fit(\n",
        "    X_train_flat, \n",
        "    y_train_oh,\n",
        "    batch_size=512, \n",
        "    epochs=40,\n",
        "    validation_data=(X_val_flat, y_val_oh),\n",
        "    callbacks=[keras_utils.TqdmProgressCallback()],\n",
        "    verbose=0\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/40\n",
            "**************************************************\n",
            "loss: 1.3300; acc: 0.6438; val_loss: 0.5187; val_acc: 0.8817\n",
            "\n",
            "Epoch 2/40\n",
            "**************************************************\n",
            "loss: 0.4114; acc: 0.8933; val_loss: 0.3022; val_acc: 0.9181\n",
            "\n",
            "Epoch 3/40\n",
            "**************************************************\n",
            "loss: 0.2978; acc: 0.9160; val_loss: 0.2473; val_acc: 0.9293\n",
            "\n",
            "Epoch 4/40\n",
            "**************************************************\n",
            "loss: 0.2513; acc: 0.9269; val_loss: 0.2188; val_acc: 0.9374\n",
            "\n",
            "Epoch 5/40\n",
            "**************************************************\n",
            "loss: 0.2224; acc: 0.9353; val_loss: 0.1995; val_acc: 0.9432\n",
            "\n",
            "Epoch 6/40\n",
            "**************************************************\n",
            "loss: 0.1975; acc: 0.9423; val_loss: 0.1830; val_acc: 0.9482\n",
            "\n",
            "Epoch 7/40\n",
            "**************************************************\n",
            "loss: 0.1786; acc: 0.9477; val_loss: 0.1678; val_acc: 0.9531\n",
            "\n",
            "Epoch 8/40\n",
            "**************************************************\n",
            "loss: 0.1610; acc: 0.9526; val_loss: 0.1542; val_acc: 0.9570\n",
            "\n",
            "Epoch 9/40\n",
            "**************************************************\n",
            "loss: 0.1458; acc: 0.9570; val_loss: 0.1449; val_acc: 0.9576\n",
            "\n",
            "Epoch 10/40\n",
            "**************************************************\n",
            "loss: 0.1319; acc: 0.9608; val_loss: 0.1328; val_acc: 0.9617\n",
            "\n",
            "Epoch 11/40\n",
            "**************************************************\n",
            "loss: 0.1198; acc: 0.9653; val_loss: 0.1272; val_acc: 0.9635\n",
            "\n",
            "Epoch 12/40\n",
            "**************************************************\n",
            "loss: 0.1097; acc: 0.9681; val_loss: 0.1181; val_acc: 0.9665\n",
            "\n",
            "Epoch 13/40\n",
            "**************************************************\n",
            "loss: 0.0991; acc: 0.9711; val_loss: 0.1120; val_acc: 0.9679\n",
            "\n",
            "Epoch 14/40\n",
            "**************************************************\n",
            "loss: 0.0900; acc: 0.9744; val_loss: 0.1083; val_acc: 0.9684\n",
            "\n",
            "Epoch 15/40\n",
            "**************************************************\n",
            "loss: 0.0825; acc: 0.9763; val_loss: 0.1032; val_acc: 0.9693\n",
            "\n",
            "Epoch 16/40\n",
            "**************************************************\n",
            "loss: 0.0750; acc: 0.9782; val_loss: 0.1008; val_acc: 0.9706\n",
            "\n",
            "Epoch 17/40\n",
            "**************************************************\n",
            "loss: 0.0680; acc: 0.9806; val_loss: 0.0971; val_acc: 0.9723\n",
            "\n",
            "Epoch 18/40\n",
            "**************************************************\n",
            "loss: 0.0620; acc: 0.9824; val_loss: 0.0909; val_acc: 0.9729\n",
            "\n",
            "Epoch 19/40\n",
            "**************************************************\n",
            "loss: 0.0564; acc: 0.9844; val_loss: 0.0883; val_acc: 0.9744\n",
            "\n",
            "Epoch 20/40\n",
            "**************************************************\n",
            "loss: 0.0513; acc: 0.9858; val_loss: 0.0870; val_acc: 0.9748\n",
            "\n",
            "Epoch 21/40\n",
            "**************************************************\n",
            "loss: 0.0468; acc: 0.9876; val_loss: 0.0858; val_acc: 0.9744\n",
            "\n",
            "Epoch 22/40\n",
            "**************************************************\n",
            "loss: 0.0425; acc: 0.9889; val_loss: 0.0846; val_acc: 0.9741\n",
            "\n",
            "Epoch 23/40\n",
            "**************************************************\n",
            "loss: 0.0393; acc: 0.9897; val_loss: 0.0839; val_acc: 0.9762\n",
            "\n",
            "Epoch 24/40\n",
            "**************************************************\n",
            "loss: 0.0354; acc: 0.9914; val_loss: 0.0882; val_acc: 0.9736\n",
            "\n",
            "Epoch 25/40\n",
            "**************************************************\n",
            "loss: 0.0328; acc: 0.9922; val_loss: 0.0786; val_acc: 0.9775\n",
            "\n",
            "Epoch 26/40\n",
            "**************************************************\n",
            "loss: 0.0291; acc: 0.9931; val_loss: 0.0778; val_acc: 0.9778\n",
            "\n",
            "Epoch 27/40\n",
            "**************************************************\n",
            "loss: 0.0262; acc: 0.9943; val_loss: 0.0795; val_acc: 0.9777\n",
            "\n",
            "Epoch 28/40\n",
            "**************************************************\n",
            "loss: 0.0234; acc: 0.9950; val_loss: 0.0804; val_acc: 0.9772\n",
            "\n",
            "Epoch 29/40\n",
            "**************************************************\n",
            "loss: 0.0218; acc: 0.9953; val_loss: 0.0753; val_acc: 0.9790\n",
            "\n",
            "Epoch 30/40\n",
            "**************************************************\n",
            "loss: 0.0196; acc: 0.9959; val_loss: 0.0773; val_acc: 0.9781\n",
            "\n",
            "Epoch 31/40\n",
            "**************************************************\n",
            "loss: 0.0173; acc: 0.9970; val_loss: 0.0761; val_acc: 0.9787\n",
            "\n",
            "Epoch 32/40\n",
            "**************************************************\n",
            "loss: 0.0155; acc: 0.9977; val_loss: 0.0770; val_acc: 0.9786\n",
            "\n",
            "Epoch 33/40\n",
            "**************************************************\n",
            "loss: 0.0139; acc: 0.9977; val_loss: 0.0772; val_acc: 0.9772\n",
            "\n",
            "Epoch 34/40\n",
            "**************************************************\n",
            "loss: 0.0135; acc: 0.9974; val_loss: 0.0768; val_acc: 0.9781\n",
            "\n",
            "Epoch 35/40\n",
            "**************************************************\n",
            "loss: 0.0115; acc: 0.9986; val_loss: 0.0775; val_acc: 0.9785\n",
            "\n",
            "Epoch 36/40\n",
            "**************************************************\n",
            "loss: 0.0106; acc: 0.9986; val_loss: 0.0781; val_acc: 0.9784\n",
            "\n",
            "Epoch 37/40\n",
            "**************************************************\n",
            "loss: 0.0095; acc: 0.9989; val_loss: 0.0771; val_acc: 0.9797\n",
            "\n",
            "Epoch 38/40\n",
            "**************************************************\n",
            "loss: 0.0083; acc: 0.9992; val_loss: 0.0755; val_acc: 0.9806\n",
            "\n",
            "Epoch 39/40\n",
            "**************************************************\n",
            "loss: 0.0074; acc: 0.9993; val_loss: 0.0771; val_acc: 0.9794\n",
            "\n",
            "Epoch 40/40\n",
            "**************************************************\n",
            "loss: 0.0066; acc: 0.9994; val_loss: 0.0748; val_acc: 0.9805\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f901f5adfd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbVzzhzHqxHW",
        "colab_type": "text"
      },
      "source": [
        "# Here're the notes for those who want to play around here\n",
        "\n",
        "Here are some tips on what you could do:\n",
        "\n",
        " * __Network size__\n",
        "   * More neurons, \n",
        "   * More layers, ([docs](https://keras.io/))\n",
        "\n",
        "   * Other nonlinearities in the hidden layers\n",
        "     * tanh, relu, leaky relu, etc\n",
        "   * Larger networks may take more epochs to train, so don't discard your net just because it could didn't beat the baseline in 5 epochs.\n",
        "\n",
        "\n",
        " * __Early Stopping__\n",
        "   * Training for 100 epochs regardless of anything is probably a bad idea.\n",
        "   * Some networks converge over 5 epochs, others - over 500.\n",
        "   * Way to go: stop when validation score is 10 iterations past maximum\n",
        "     \n",
        "\n",
        " * __Faster optimization__\n",
        "   * rmsprop, nesterov_momentum, adam, adagrad and so on.\n",
        "     * Converge faster and sometimes reach better optima\n",
        "     * It might make sense to tweak learning rate/momentum, other learning parameters, batch size and number of epochs\n",
        "\n",
        "\n",
        " * __Regularize__ to prevent overfitting\n",
        "   * Add some L2 weight norm to the loss function, theano will do the rest\n",
        "     * Can be done manually or via - https://keras.io/regularizers/\n",
        "   \n",
        "   \n",
        " * __Data augmemntation__ - getting 5x as large dataset for free is a great deal\n",
        "   * https://keras.io/preprocessing/image/\n",
        "   * Zoom-in+slice = move\n",
        "   * Rotate+zoom(to remove black stripes)\n",
        "   * any other perturbations\n",
        "   * Simple way to do that (if you have PIL/Image): \n",
        "     * ```from scipy.misc import imrotate,imresize```\n",
        "     * and a few slicing\n",
        "   * Stay realistic. There's usually no point in flipping dogs upside down as that is not the way you usually see them."
      ]
    }
  ]
}